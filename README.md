SIMPLE SCRAPY CRAWLERS
==========================================
Simple scrapy crawlers that demonstrate different approaches to scraping content.

PREREQUISITES
================
This project was created using Scrapy 1.5.1 and Python 3.6.6.
Anaconda was used for package management and you can install all the project dependencies using the provided requirements.txt file, provided with the project.


RUNNING THE CRAWLER
====================
Once you've cloned the repository onto your machine, change directory into the Slashdot-Scraper directory and run the "scrapy crawl <spidername>" command. You can run any of the five spiders located in the "spiders" directory i.e. fast, easy, login or manual

#Commands

cd Scrapy-Scripts

scrapy crawl <easy|fast|login|manual>
